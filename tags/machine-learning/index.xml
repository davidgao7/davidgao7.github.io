<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on davidgao7 blog</title>
    <link>http://localhost:1313/tags/machine-learning/</link>
    <description>Recent content in Machine Learning on davidgao7 blog</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 26 Mar 2025 16:41:21 -0400</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Evolution of Route Planning in Urban Environments</title>
      <link>http://localhost:1313/posts/evolution-of-route-planning-in-urban-env/</link>
      <pubDate>Wed, 26 Mar 2025 16:41:21 -0400</pubDate>
      <guid>http://localhost:1313/posts/evolution-of-route-planning-in-urban-env/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Route planning is the backbone of modern transportation in megacities like Shanghai, enabling efficient navigation through complex road networks. Over the decades, the field has evolved from simple graph searches on static maps to sophisticated AI-driven systems that account for real-time data and even integrate large language models. This report provides a chronological overview of key route planning methods, from classical algorithms (breadth-first search, Dijkstra’s algorithm, etc.) to cutting-edge approaches (reinforcement learning, deep learning, and LLM-assisted planning). For each method, we summarize the main idea in one sentence, present core mathematical details (with annotated formulas), and give a theoretical example alongside a real-world example. We then discuss how Large Language Models (LLMs) are being incorporated into route planning (with academic and industrial citations), followed by an analysis of Baidu’s advancements in route planning (including deployments in cities like Shanghai and performance metrics). Finally, we compare Baidu’s work with global leaders (Google, Tesla, Amazon, Apple), identify gaps and their causes (data, regulatory, tech stack), and suggest steps to bridge these gaps. Key breakthroughs and paradigm shifts are highlighted throughout. Relevant codebases (especially Python implementations) are linked for further exploration.&lt;/p&gt;</description>
    </item>
    <item>
      <title>SVM</title>
      <link>http://localhost:1313/posts/svm/</link>
      <pubDate>Fri, 07 Feb 2025 20:44:54 -0500</pubDate>
      <guid>http://localhost:1313/posts/svm/</guid>
      <description>&lt;h1 id=&#34;support-vector-machine-classifier&#34;&gt;Support Vector Machine (Classifier)&lt;/h1&gt;&#xA;&lt;p&gt;suggest readings:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Alpaydin: 10.3, 13.1, 13.2&lt;/li&gt;&#xA;&lt;li&gt;Murphy: 14.5.2.2&lt;/li&gt;&#xA;&lt;li&gt;Geron: chapter 5, appendix C&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;alpaydin-阅读笔记&#34;&gt;Alpaydin 阅读笔记&lt;/h2&gt;&#xA;&lt;h3 id=&#34;geometry-of-the-linear-discriminant-线性可区分的图像&#34;&gt;Geometry of the Linear Discriminant （线性可区分的图像）&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;从一个简单的 two classes 情况开始解析，在这种情况下，单个的区分方程已经足够：&lt;/li&gt;&#xA;&lt;li&gt;Discriminant between two classes:&#xA;$$&#xA;\begin{equation}\label{Discriminant_between_two_classes}&#xA;\begin{split}&#xA;g(\chi) &amp;= g_1(\chi) - g_2(\chi)\\&#xA;        &amp;= ((w_1)^T\chi + w_{10}) - ((w_2)^T\chi + w_{20})\\&#xA;        &amp;= (w_1 - w_2)^T\chi + (w_{10} - w_{20})\\&#xA;        &amp;= w^T\chi + w_0&#xA;\end{split}&#xA;\end{equation}&#xA;$$&lt;/li&gt;&#xA;&lt;li&gt;we choose&#xA;$$&#xA;\left.&#xA;        \begin{matrix}&#xA;            C_1,\text{ }g(\chi) &gt; 0\\&#xA;            C_2,\text{ }otherwise&#xA;        \end{matrix}&#xA;\right\}&#xA;$$&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;code&gt;weight vector threshold&lt;/code&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
